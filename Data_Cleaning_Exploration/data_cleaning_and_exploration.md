My goal is to run sentiment analysis on the reviews of the biggest games and see how they differ between the games as well between positive vs. negative reviews. To prep the data, I decided to drop any reviews that weren't in english, as well as any reviews that included symbols that could be unfamiliar for any sentiment analysis bot. The sheer size of the data was also a problem, as handling such a large set with unimportant features could lead to out of memory issues. I decided to drop columns as appid and hidden_in_steam_china which I deemed irrelevant to my overall analysis. 

I also had an idea to run a pretrained LLM to see how well a model could classify the reviews by game, as well as if it was positive review or negative review, and maybe run an XAI approach to dissect its decision making. I did some exploratory data analysis to see the class balance, and my visualizations show that Counter Strike 2 has a high plurality within the dataset compared to other popular games. I also saw that a lot of these games have an overwhelming positive review proportion, other than PUBG for some reason (probably because of the cheater scandals). These aren't necessarily deal breakers for fitting a model onto, but they make it more difficult to evaluate how well the model learned. Fortunately, I saw that negative reviews were associated with a signficantly higher word count, which indicates that a model might be able to pick up on that to differentiate negative reviews from positive ones. 